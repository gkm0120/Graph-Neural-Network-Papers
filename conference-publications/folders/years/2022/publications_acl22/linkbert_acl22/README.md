# LinkBERT: Pretraining Language Models with Document Links

```
@inproceedings{linkbert_acl22,
title = {{L}ink{BERT}: Pretraining Language Models with Document Links},
author = {Yasunaga, Michihiro and Leskovec, Jure and Liang, Percy},
booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL)},
pages = {8003--8016},
year = {2022}
}
```

links
- [aclweb](https://www.aclweb.org/anthology/2022.acl-long.551/)
- [arxiv](https://arxiv.org/abs/2203.15827)
