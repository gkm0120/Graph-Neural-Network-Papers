# Lipschitz normalization for self-attention layers with application to graph neural networks

```
@inproceedings{lipschitznorm_icml21,
title = {Lipschitz normalization for self-attention layers with application to graph neural networks},
author = {Dasoulas, George and Scaman, Kevin and Virmaux, Aladin},
booktitle = {Proceedings of the 38th International Conference on Machine Learning (ICML)},
pages = {2456--2466},
year = {2021}
}
```

links
- [pmlr](http://proceedings.mlr.press/v139/dasoulas21a.html)
- [icml](https://icml.cc/virtual/2021/poster/8537)
- [arXiv](https://arxiv.org/abs/2103.04886)