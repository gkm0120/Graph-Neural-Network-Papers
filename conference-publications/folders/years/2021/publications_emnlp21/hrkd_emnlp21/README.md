# HRKD: Hierarchical Relational Knowledge Distillation for Cross-domain Language Model Compression

```
@inproceedings{hrkd_emnlp21,
title = {{HRKD}: Hierarchical Relational Knowledge Distillation for Cross-domain Language Model Compression},
author = {Dong, Chenhe and Li, Yaliang and Shen, Ying and Qiu, Minghui},
booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
pages = {3126--3136},
year = {2021}
}
```

links
- [acl](https://aclanthology.org/2021.emnlp-main.250)
